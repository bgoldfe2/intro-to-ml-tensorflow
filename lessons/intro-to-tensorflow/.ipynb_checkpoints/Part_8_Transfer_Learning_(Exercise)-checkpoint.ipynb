{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2muxqaxvTlzk"
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solve challenging problems in computer vision. Specifically, you'll use a network trained on [ImageNet](http://www.image-net.org/). ImageNet is a massive dataset with over 1 million labeled images in 1,000 categories.\n",
    "\n",
    "These pre-trained models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called **Transfer Learning**. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With [TensorFlow Hub](https://www.tensorflow.org/hub) you can download these pre-trained networks and use them in your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QNYGxmtIXQP"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmUJmdTpU1Pz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:50:02.599321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'monitoring'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53305/549463114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_module_for_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_embedding_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_hub/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \"\"\"Regularly exports registered modules into timestamped directories.\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_estimator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselineClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselineEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEstimatorSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Track the adoption of TPUEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m _tpu_estimator_gauge = tf.compat.v2.__internal__.monitoring.BoolGauge(\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;34m'/tensorflow/api/tpu_estimator'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     'Whether the program uses tpu estimator or not.')\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'monitoring'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_Abet3-Yydgw",
    "outputId": "266644f2-f473-4353-87a4-cf07385c1492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.4.1\n",
      "\t• tf.keras version: 2.4.0\n",
      "\t• Running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 19:25:11.666661: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-25 19:25:11.669112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-25 19:25:11.728551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:25:11.729588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-25 19:25:11.729625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-25 19:25:11.732251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-25 19:25:11.732326: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-25 19:25:11.734809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-25 19:25:11.735205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-25 19:25:11.737806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-25 19:25:11.739387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-25 19:25:11.743087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-25 19:25:11.743231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:25:11.743786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:25:11.744242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-25 19:25:11.744280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-25 19:30:08.866877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-25 19:30:08.866901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-25 19:30:08.866907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-25 19:30:08.867294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:30:08.867786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:30:08.868248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:30:08.868675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 6661 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6)\n",
      "2021-09-25 19:30:08.869638: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMr2MeTCIhJd"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hrbFmp_2WJCc",
    "outputId": "80ce0d69-ce2d-4f4e-bff5-89b622e54110"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Split' has no attribute 'ALL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35116/28705893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_val_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cats_vs_dogs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Split' has no attribute 'ALL'"
     ]
    }
   ],
   "source": [
    "train_split = 60\n",
    "test_val_split = 20\n",
    "\n",
    "splits = tfds.Split.ALL.subsplit([60,20, 20])\n",
    "\n",
    "(training_set, validation_set, test_set), dataset_info = tfds.load('cats_vs_dogs', split=splits, as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 19:31:43.326587: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-25 19:31:43.326750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.327315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-25 19:31:43.327348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-25 19:31:43.327368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-25 19:31:43.327379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-25 19:31:43.327390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-25 19:31:43.327401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-25 19:31:43.327411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-25 19:31:43.327422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-25 19:31:43.327432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-25 19:31:43.327492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.328045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.328536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-25 19:31:43.328794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.329327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-25 19:31:43.329349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-25 19:31:43.329361: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-25 19:31:43.329371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-25 19:31:43.329380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-25 19:31:43.329390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-25 19:31:43.329399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-25 19:31:43.329409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-25 19:31:43.329419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-25 19:31:43.329508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.330161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.330746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-25 19:31:43.330779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-25 19:31:43.330786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-25 19:31:43.330791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-25 19:31:43.330889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.331508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:31:43.332069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6661 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6)\n",
      "2021-09-25 19:31:43.332088: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "dataset, dataset_info = tfds.load('fashion_mnist', split=[ 'train[:60%]+test[:60%]','train[60%:80%]+test[60%:80%]','train[80%:100%]+test[80%:100%]'], as_supervised=True, with_info=True)\n",
    "training_set, validation_set, test_set = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yotXUFkbI-9B"
   },
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "V7Vii2eIEBPl",
    "outputId": "9f70bea5-b3e1-4f7a-de91-1ff43f563a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    full_name='fashion_mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    data_path='/home/bruce/tensorflow_datasets/fashion_mnist/3.0.1',\n",
       "    download_size=29.45 MiB,\n",
       "    dataset_size=36.42 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_LOJzPsiiz2Q",
    "outputId": "e58cf5d3-7b5f-4249-b016-cabcee549dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset has a total of:\n",
      "• 10 classes\n",
      "• 60,000 images\n"
     ]
    }
   ],
   "source": [
    "num_classes = dataset_info.features['label'].num_classes\n",
    "total_num_examples = dataset_info.splits['train'].num_examples\n",
    "\n",
    "print('The Dataset has a total of:')\n",
    "print('\\u2022 {:,} classes'.format(num_classes))\n",
    "print('\\u2022 {:,} images'.format(total_num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KccTIDXNVUk3"
   },
   "source": [
    "As a technical note, if the total number of examples in your dataset is not a multiple of 100 (*i.e.* if `total_num_examples % 100 != 0`), then TensorFlow may not evenly distribute the data among subsplits. As we can see, our dataset has `23,262` examples, which is not a multiple of 100. Therefore, in this particular case, we should expect that our data would not be evenly distributed among the subsplits that we created. This means that even though we set our `split` to allocate 60\\% of the data to the training set, 20\\% of the data to the validation set, and 20\\% of the data to the test set, the actual number of images in each set may vary from these percentages. It is important to note, that these small differences will not affect our training process. We didn't have this issue before when we worked the MNIST and Fashion-MNIST datasets because both of these datasets had 70,000 examples. Since 70,000 is a multiple of 100, then the data was evenly distributed in both of those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lECJGR1hdaJH"
   },
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "IRoQodo3dXY2",
    "outputId": "6957ba36-81cf-47d0-b8a9-f1547bb22dc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 19:32:43.935147: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-09-25 19:32:43.956333: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3299865000 Hz\n",
      "2021-09-25 19:32:43.994866: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this image is: 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35116/3545094051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The label of this image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The class name of this image is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', label)\n",
    "print('The class name of this image is:', class_names[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXdiexgZBnAq"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The pre-trained model we are going to use requires that the input images have color values in the range `[0,1]` and a size of `(224, 224)`. We will therefore have to normalize the pixel values of our images and resize them to the appropriate size. We can normalize our pixel values in the usual way by dividing the original pixel values by `255` and to resize our images we can use the `tf.image.resize()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "kkGBYnL-BqH1",
    "outputId": "3d3fdbd5-7c7f-4ba1-e842-1a4877f5c20a"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 224\n",
    "\n",
    "num_training_examples = (total_num_examples * train_split) // 100\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "training_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(batch_size).prefetch(1)\n",
    "validation_batches = validation_set.map(format_image).batch(batch_size).prefetch(1)\n",
    "testing_batches = test_set.map(format_image).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OFVEQQSleKF"
   },
   "source": [
    "## Transfer Learning with TensorFlow Hub\n",
    "\n",
    "[TensorFlow Hub](https://www.tensorflow.org/hub) is an online repository of pre-trained models. In addition to complete pre-trained models, TensorFlow Hub also contains models without the last classification layer. These models can be used to perform transfer learning by adding a classification layer that suits the number of classes in your particular dataset. You can take a look at all the models available for TensorFlow 2.0 in [TensorFlow Hub](https://tfhub.dev/s?q=tf2-preview).\n",
    "\n",
    "In this notebook, we will use a network trained on the ImageNet dataset called MobileNet. MobileNet is a state-of-the-art convolutional neural network developed by Google. Convolutional neural networks are out of the scope of this course, but if you want to learn more about them, you can take a look at this [video](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "In the cell below we download the pre-trained MobileNet model without the final classification layer from TensorFlow Hub using the `hub.KerasLayer(URL)` function. This function downloads the desired model form the given TensorFlow Hub `URL` and wraps it in a Keras layer so that we can integrate it in a `tf.keras` Sequential model later. Since this will be the first layer of our Sequential model, we need to specify the `input_shape` parameter. The shape of our input tensor must match the size of the images MobileNet was trained on, namely `(224,224,3)`. \n",
    "\n",
    "Our pre-trained model will be responsible for extracting the features of our images, we will therefore call this part of our model the `feature_extractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59qI5xtTBjk7"
   },
   "outputs": [],
   "source": [
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "feature_extractor = hub.KerasLayer(URL, input_shape=(image_size, image_size,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTJTOxkfnlgd"
   },
   "source": [
    "It is important that we freeze the weights and biases in our pre-trained model so that we don't modify them during training. We can do this by setting the parameters of our model to non-trainable, as shown in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqtAGNlZnjvE"
   },
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VEEN4oUoZMW"
   },
   "source": [
    "## Build the Model\n",
    "\n",
    "We will now create a `tf.keras` Sequential model with our `feature_extractor` and a new classification layer. Since our dataset only has 2 classes (cat and dog) we create an output layer with only 2 units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "le6eV8RfoQHc",
    "outputId": "16eadcdf-35f9-450c-c121-cb52d872b778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7efe18050760>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSy0p05YpDmM"
   },
   "source": [
    "## Train the Model Using a GPU\n",
    "\n",
    "With our model built, we now need to train the new classification layer, but this time we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use a GPU to do the calculations. On a GPU, linear algebra computations are done in parallel, leading to 100x increased training speeds. TensorFlow will transparently run on a single GPU without requiring that we make changes to our code. With TensorFlow, it's also possible to train on multiple GPUs, further decreasing training time, but this requires that we make changes to our code to incorporate [distributed training](https://www.tensorflow.org/guide/distributed_training). \n",
    "\n",
    "We can use the `tf.test.is_gpu_available()` function to confirm that TensorFlow is using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7BsmVnFCrT5u",
    "outputId": "8c25a339-afe6-487b-a6c0-203a05c7f651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a GPU Available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 19:32:58.825366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:32:58.825839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2021-09-25 19:32:58.825893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-09-25 19:32:58.825927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-09-25 19:32:58.825952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-09-25 19:32:58.825974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-25 19:32:58.825997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-25 19:32:58.826019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-09-25 19:32:58.826040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-09-25 19:32:58.826062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-09-25 19:32:58.826191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:32:58.826678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:32:58.827044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-09-25 19:32:58.827089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-25 19:32:58.827102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-09-25 19:32:58.827113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-09-25 19:32:58.827289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:32:58.827782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-25 19:32:58.828185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 6661 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:09:00.0, compute capability: 8.6)\n",
      "2021-09-25 19:32:58.828220: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print('Is there a GPU Available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3BA5rWQuVaF"
   },
   "source": [
    "TensorFlow uses different string identifiers for CPUs and GPUs. For example, TensorFlow will use the identifier:\n",
    "\n",
    "```python\n",
    "'/CPU:0'\n",
    "```\n",
    "for the CPU of your machine; and it will use the identifier:\n",
    "\n",
    "```python\n",
    "'/GPU:0'\n",
    "```\n",
    "for the first GPU of your machine that is visible to TensorFlow. If your system has both devices, `/CPU:0` and `/GPU:0`, by default the GPU devices will be given priority when preforming TensorFlow operations (given that the TensorFlow operations have both CPU and GPU implementations). For example, the TensorFlow `tf.matmul` operation has both CPU and GPU kernels, therefore, the `/GPU:0` device will be selected to run `tf.matmul` unless you explicitly request running it on another device.\n",
    "\n",
    "### Manual Device Placement\n",
    "\n",
    "If you would like a particular TensorFlow operation to run on the device of your choice, instead of what's automatically selected for you by default, you can use:\n",
    "\n",
    "```python\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    perform operations\n",
    "```\n",
    "\n",
    "to have operations run on the CPU; and you can use:\n",
    "  \n",
    "```python\n",
    "# Place tensors on the GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    perform operations\n",
    "```\n",
    "\n",
    "to have operations run on the GPU.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Let's assume we have a system that has both devices, `/CPU:0` and `/GPU:0`. What will happen if we run the code below?\n",
    "\n",
    "```python\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal(...)\n",
    "    b = tf.random.normal(...)\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "```\n",
    "\n",
    "The above code will create both `a` and `b` using the CPU because we manually assigned those statements to the \n",
    "`/CPU:0` device using the `with tf.device('/CPU:0')` code block. However, since the statement `c = tf.matmul(a, b)` is NOT inside the `with tf.device('/CPU:0')` code block, then TensorFlow will run the `tf.matmul` operation on the `/GPU:0` device. TensorFlow will automatically copy tensors between devices if required.\n",
    "\n",
    "In the code below, we will multiply matrices of increasing size using both the CPU and GPU so you can see the difference in execution time. You will see, that as the size of the matrices increase, the execution time on the CPU increases rapidly, but on the GPU it stays constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 19:33:05.632082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "def plot_times(max_size = 650):\n",
    "    device_times = {'/GPU:0':[], '/CPU:0':[]}\n",
    "    matrix_sizes = range(450, max_size, 50)\n",
    "    len_matrix = len(matrix_sizes)\n",
    "\n",
    "    for i, size in enumerate(matrix_sizes):\n",
    "        for device_name in device_times.keys():\n",
    "            with tf.device(device_name):\n",
    "                m1 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n",
    "                m2 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n",
    "                start_time = time.time()\n",
    "                dot_operation = tf.matmul(m2, m1)\n",
    "                time_taken = time.time() - start_time\n",
    "                \n",
    "                if i > 0:\n",
    "                    device_times[device_name].append(time_taken)\n",
    "                    \n",
    "        percent_complete = (i + 1) / len_matrix\n",
    "        print('\\rPerforming Calculations. Please Wait... {:.0%} Complete'.format(percent_complete), end = '')\n",
    "    \n",
    "    matrix_sizes = matrix_sizes[1:]\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    plt.plot(matrix_sizes, device_times['/CPU:0'], 'o-', color='magenta', linewidth = 2, label = 'CPU')\n",
    "    plt.plot(matrix_sizes, device_times['/GPU:0'], 'o-', color='cyan', linewidth = 2, label='GPU')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('black')\n",
    "    plt.grid()\n",
    "    plt.ylabel('Time (s)', color='white', fontsize = 20)\n",
    "    plt.xlabel('Matrix size',  color='white', fontsize = 20)\n",
    "    plt.legend(prop={'size': 15})\n",
    "    plt.show()\n",
    "    \n",
    "plot_times(850)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUaXuhBorKXr"
   },
   "source": [
    "From here, I'll let you finish training the model. The process is the same as before except that now your model will automatically run on the GPU. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train the `model` we created above to classify the cat and dog images in our dataset. Because we are using a pre-trained model, you will only need to train the model for a few epochs to get a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "zsNPAHR9o7Gv",
    "outputId": "3de71c8e-56d0-495f-d386-ab400b14e4ba"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBfxg0GoPdiO"
   },
   "source": [
    "# Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "colab_type": "code",
    "id": "X_eKgwBe880Q",
    "outputId": "c48c3728-03ed-4c1c-df01-282196f75520"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    ps = model.predict(image_batch)\n",
    "    images = image_batch.numpy().squeeze()\n",
    "    labels = label_batch.numpy()\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(images[n], cmap = plt.cm.binary)\n",
    "    color = 'green' if np.argmax(ps[n]) == labels[n] else 'red'\n",
    "    plt.title(class_names[np.argmax(ps[n])], color=color)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41kBLcTJVX3y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 8 - Transfer Learning (Solution).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TF2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
